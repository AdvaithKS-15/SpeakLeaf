[{"index": 0, "sentence": "MicroScan: AI-Powered Mobile Microplastic Detector\nOne-Line Pitch\nEmpower citizen scientists to monitor environmental pollution: a smartphone app with a cheap microscope attachment uses AI to identify and quantify microplastic particles in water or soil samples.", "start": 0, "duration": 22.32}, {"index": 1, "sentence": "Problem Statement\n(Microplastics Pictures | Download Free Images on Unsplash)Microplastic pollution is pervasive and poses serious health and environmental risks.", "start": 22.32, "duration": 12.888}, {"index": 2, "sentence": "Studies show tiny plastic fragments (<5 mm) are found in oceans, rivers, soil, food, and even tap water and the human body ( Deep-learning enabled rapid and low-cost detection of microplastics in consumer products following on-site extraction and image processing - PMC ) (Northwest scientists develop a device that detects microplastics in water - OPB).", "start": 35.208, "duration": 31.248}, {"index": 3, "sentence": "Traditional detection methods rely on expensive lab equipment (e.g.", "start": 66.456, "duration": 5.496}, {"index": 4, "sentence": "electron microscopes, spectroscopy) and skilled operators, making frequent monitoring impractical ( Deep-learning enabled rapid and low-cost detection of microplastics in consumer products following on-site extraction and image processing - PMC ).", "start": 71.952, "duration": 19.8}, {"index": 5, "sentence": "Consequently, communities and researchers lack scalable tools to measure microplastic contamination in water or consumer products.", "start": 91.752, "duration": 10.56}, {"index": 6, "sentence": "Without accessible testing, we cannot easily assess pollution hotspots or take timely action.", "start": 102.312, "duration": 7.392}, {"index": 7, "sentence": "A low-cost, portable solution could enable widespread testing (e.g.", "start": 109.704, "duration": 5.928}, {"index": 8, "sentence": "in schools, farms or by concerned citizens) to raise awareness and guide mitigation.", "start": 115.63199999999999, "duration": 6.864}, {"index": 9, "sentence": "Proposed Solution\nWe propose MicroScan, a mobile AI system that turns any smartphone into a microplastic detector.", "start": 122.496, "duration": 10.008}, {"index": 10, "sentence": "Users filter a water or soil sample through a fine membrane, attach a low-cost clip-on microscope lens (e.g.", "start": 132.504, "duration": 8.928}, {"index": 11, "sentence": "a $10 “.” or homemade 3D-printed lens), and capture an image of the residue.", "start": 141.432, "duration": 6.744}, {"index": 12, "sentence": "The app processes the image to highlight and count microplastic fragments using a deep-learning object detector.", "start": 148.176, "duration": 8.496}, {"index": 13, "sentence": "Drawing on recent research, we will train a convolutional neural network (e.g.", "start": 156.672, "duration": 6.384}, {"index": 14, "sentence": "YOLOv5/YOLOv8) on images of microplastics ( Deep-learning enabled rapid and low-cost detection of microplastics in consumer products following on-site extraction and image processing - PMC ).", "start": 163.05599999999998, "duration": 16.488}, {"index": 15, "sentence": "The AI highlights plastic particles in the photo and estimates their size/count.", "start": 179.54399999999998, "duration": 6.624}, {"index": 16, "sentence": "Results (particle count, estimated volume) are displayed to the user.", "start": 186.16799999999998, "duration": 6.192}, {"index": 17, "sentence": "Optionally, MicroScan can log GPS-tagged results to a shared cloud database or map, enabling crowdsourced tracking of microplastic “hotspots.” We may also integrate a simple recommendation engine or chatbot (e.g.", "start": 192.35999999999999, "duration": 18.648}, {"index": 18, "sentence": "using an LLM) to explain results or suggest actions (e.g.", "start": 211.00799999999998, "duration": 6.024}, {"index": 19, "sentence": "filter tips, local recycling info).", "start": 217.03199999999998, "duration": 3.384}, {"index": 20, "sentence": "By combining off-the-shelf hardware with proven AI techniques, MicroScan aims to make microplastic testing fast, accurate, and widely accessible ( Deep-learning enabled rapid and low-cost detection of microplastics in consumer products following on-site extraction and image processing - PMC ) (Northwest scientists develop a device that detects microplastics in water - OPB).", "start": 220.41599999999997, "duration": 29.712}, {"index": 21, "sentence": "Key AI/ML Technologies to Use\nComputer Vision / Object Detection: A deep CNN (e.g.", "start": 250.12799999999996, "duration": 9.624}, {"index": 22, "sentence": "YOLOv5 or YOLOv8) to identify and localize microplastic particles in microscope images ( Deep-learning enabled rapid and low-cost detection of microplastics in consumer products following on-site extraction and image processing - PMC ).", "start": 259.75199999999995, "duration": 19.488}, {"index": 23, "sentence": "YOLO models are fast and suitable for mobile deployment (with ONNX or TensorFlow-Lite).", "start": 279.23999999999995, "duration": 7.488}, {"index": 24, "sentence": "Transfer Learning: Fine-tune pre-trained object-detection models on a custom microplastics dataset to recognize various shapes and colors of particles.", "start": 286.72799999999995, "duration": 12.192}, {"index": 25, "sentence": "Use data augmentation (rotations, noise) to improve robustness.", "start": 298.91999999999996, "duration": 6.048}, {"index": 26, "sentence": "Image Processing: Use OpenCV or similar libraries for preprocessing (e.g.", "start": 304.96799999999996, "duration": 6.84}, {"index": 27, "sentence": "filtering out debris, enhancing contrast) and post-processing (e.g.", "start": 311.80799999999994, "duration": 6.24}, {"index": 28, "sentence": "counting and sizing blobs).", "start": 318.04799999999994, "duration": 2.208}, {"index": 29, "sentence": "Machine Learning on Edge/Cloud: Depending on performance needs, run the detection model on-device (for low latency and offline use) or on a cloud server.", "start": 320.256, "duration": 12.84}, {"index": 30, "sentence": "Utilize ONNX Runtime or TensorFlow Lite for efficient on-phone inference.", "start": 333.09599999999995, "duration": 6.648}, {"index": 31, "sentence": "Data Management & Analytics: A lightweight backend (e.g.", "start": 339.74399999999997, "duration": 5.04}, {"index": 32, "sentence": "Python/Flask or Firebase) to store user submissions and aggregate results.", "start": 344.784, "duration": 6.744}, {"index": 33, "sentence": "Possibly use simple clustering algorithms or GIS visualization for the crowdsourced dataset.", "start": 351.528, "duration": 7.872}, {"index": 34, "sentence": "User Interaction (Optional): A language model (e.g.", "start": 359.40000000000003, "duration": 4.896}, {"index": 35, "sentence": "GPT-4 API) or rule-based chatbot to translate results into health/environment insights or recommendations.", "start": 364.29600000000005, "duration": 10.032}, {"index": 36, "sentence": "Architecture Overview\nMobile App (Front-End): React Native or native Android/iOS app with camera interface.", "start": 374.32800000000003, "duration": 9.888}, {"index": 37, "sentence": "Guides user through sample prep, captures image with microscope attachment, and displays detection results.", "start": 384.216, "duration": 8.472}, {"index": 38, "sentence": "Provides visualization (e.g.", "start": 392.688, "duration": 3.0}, {"index": 39, "sentence": "bounding boxes around plastics) and numeric summaries (particle count, estimated mass).", "start": 395.688, "duration": 7.68}, {"index": 40, "sentence": "Optionally includes a map or feed of recent scans.", "start": 403.368, "duration": 4.224}, {"index": 41, "sentence": "Image Capture Module: Integrate smartphone camera APIs to capture high-resolution microscope images.", "start": 407.592, "duration": 8.064}, {"index": 42, "sentence": "Calibrate for lighting and focus to ensure clarity of tiny particles.", "start": 415.656, "duration": 5.232}, {"index": 43, "sentence": "On-Device AI Module: Embed the trained YOLO model (exported to ONNX/TFLite) within the app.", "start": 420.88800000000003, "duration": 9.312}, {"index": 44, "sentence": "When an image is taken, the app runs the model locally to detect microplastic fragments in real time.", "start": 430.20000000000005, "duration": 8.304}, {"index": 45, "sentence": "This avoids the need for internet connectivity in the field.", "start": 438.504, "duration": 4.176}, {"index": 46, "sentence": "Backend Server (Optional): A cloud server (AWS/GCP or Firebase) for heavier computation and data storage.", "start": 442.68, "duration": 11.112}, {"index": 47, "sentence": "It can handle:\nModel Training Pipeline: Store labeled images; retrain/improve the model with new data.", "start": 453.79200000000003, "duration": 8.88}, {"index": 48, "sentence": "Result Logging: Collect anonymous user data to build a heatmap of microplastic levels.", "start": 462.672, "duration": 7.224}, {"index": 49, "sentence": "APIs: Offer endpoints for image upload/inference if on-device processing is not viable.", "start": 469.896, "duration": 7.632}, {"index": 50, "sentence": "Database: A simple database (NoSQL or Firebase) to record test results (timestamp, location, particle stats).", "start": 477.528, "duration": 11.592}, {"index": 51, "sentence": "UX/Visualization: In-app charts or graphs to track trends over time.", "start": 489.12, "duration": 6.888}, {"index": 52, "sentence": "A map view (using Google Maps API) to show aggregated pollution levels by area.", "start": 496.008, "duration": 7.008}, {"index": 53, "sentence": "Third-Party Integrations: Possibly integrate an open dataset (e.g.", "start": 503.01599999999996, "duration": 5.736}, {"index": 54, "sentence": "plastic pollution indices) or IoT sensors for correlated environmental data.", "start": 508.75199999999995, "duration": 6.84}, {"index": 55, "sentence": "Potential Challenges\nSample Preparation: Users must properly filter and prepare samples (density separation, dye use) before imaging.", "start": 515.592, "duration": 12.072}, {"index": 56, "sentence": "Ensuring a simple, safe protocol (e.g.", "start": 527.664, "duration": 3.96}, {"index": 57, "sentence": "instructions for household items) is crucial.", "start": 531.624, "duration": 3.864}, {"index": 58, "sentence": "Errors in preparation could lead to false results.", "start": 535.488, "duration": 3.72}, {"index": 59, "sentence": "Data and Labels: Training data for microplastics is scarce.", "start": 539.2080000000001, "duration": 4.944}, {"index": 60, "sentence": "We must collect or generate a diverse image dataset covering different plastic types and background materials (soil, water debris, etc.).", "start": 544.152, "duration": 11.88}, {"index": 61, "sentence": "Manual labeling of tiny fragments is tedious.", "start": 556.032, "duration": 3.84}, {"index": 62, "sentence": "We may start with published datasets (if available) or partner with researchers.", "start": 559.8720000000001, "duration": 6.552}, {"index": 63, "sentence": "Variation in Particles: Microplastics come in many colors, shapes, and transparencies.", "start": 566.4240000000001, "duration": 7.896}, {"index": 64, "sentence": "The model must generalize to unexpected appearances (e.g.", "start": 574.32, "duration": 4.872}, {"index": 65, "sentence": "fibers vs. flakes).", "start": 579.192, "duration": 2.088}, {"index": 66, "sentence": "Some plastics may look similar to organic particles.", "start": 581.28, "duration": 3.984}, {"index": 67, "sentence": "Ensuring high detection accuracy (minimizing false positives/negatives) will be challenging.", "start": 585.264, "duration": 8.016}, {"index": 68, "sentence": "Hardware Limitations: Running a deep model on a mobile device may strain CPU/GPU.", "start": 593.28, "duration": 7.752}, {"index": 69, "sentence": "We may need to optimize the model (pruning, lower resolution) to maintain real-time speeds without draining the battery.", "start": 601.0319999999999, "duration": 8.88}, {"index": 70, "sentence": "Differences across phone cameras (resolution, lens quality) could affect consistency.", "start": 609.9119999999999, "duration": 7.536}, {"index": 71, "sentence": "Illumination and Focus: Capturing sharp images of tiny plastics requires good lighting and stable focus.", "start": 617.4479999999999, "duration": 8.52}, {"index": 72, "sentence": "We may need to implement auto-exposure or flash controls.", "start": 625.9679999999998, "duration": 4.656}, {"index": 73, "sentence": "Poor image quality could hamper detection.", "start": 630.6239999999998, "duration": 3.264}, {"index": 74, "sentence": "User Variability: Non-expert users might misinterpret instructions.", "start": 633.8879999999998, "duration": 5.736}, {"index": 75, "sentence": "Providing a clear UI/UX and foolproof guides (e.g.", "start": 639.6239999999998, "duration": 4.992}, {"index": 76, "sentence": "sample video or AR guides) will be important.", "start": 644.6159999999998, "duration": 4.032}, {"index": 77, "sentence": "Why It Could Win\nNovelty & Social Impact: MicroScan addresses a critical and underexplored problem – microplastic pollution – with cutting-edge AI.", "start": 648.6479999999998, "duration": 12.648}, {"index": 78, "sentence": "Unlike typical hackathon projects (chatbots or general apps), this solution combines hardware and ML for environmental good ( Deep-learning enabled rapid and low-cost detection of microplastics in consumer products following on-site extraction and image processing - PMC ) ( Deep-learning enabled rapid and low-cost detection of microplastics in consumer products following on-site extraction and image processing - PMC ).", "start": 661.2959999999998, "duration": 32.496}, {"index": 79, "sentence": "Tackling a global crisis (plastic pollution in water and food) resonates strongly with judges interested in sustainability and innovation ( Deep-learning enabled rapid and low-cost detection of microplastics in consumer products following on-site extraction and image processing - PMC ) (Northwest scientists develop a device that detects microplastics in water - OPB).", "start": 693.7919999999998, "duration": 28.344}, {"index": 80, "sentence": "Technical Depth: The project integrates multiple advanced technologies: on-device computer vision, CNN training, mobile app development, and cloud infrastructure.", "start": 722.1359999999999, "duration": 13.08}, {"index": 81, "sentence": "Optimizing a YOLO model for real-time edge inference and dealing with tiny object detection demonstrates significant engineering skill.", "start": 735.2159999999999, "duration": 9.888}, {"index": 82, "sentence": "The architecture’s hybrid design (edge + cloud) shows ambitious scope.", "start": 745.1039999999999, "duration": 6.336}, {"index": 83, "sentence": "Feasibility & Prototype Potential: All components leverage existing tools.", "start": 751.4399999999999, "duration": 6.144}, {"index": 84, "sentence": "Low-cost microscope clips exist and YOLO models can be trained within days.", "start": 757.584, "duration": 6.024}, {"index": 85, "sentence": "The team’s strong full-stack and data science skills make a working demo achievable within a hackathon/MVP timeframe.", "start": 763.608, "duration": 9.408}, {"index": 86, "sentence": "For example, a Flask server with a YOLOv5 prototype and an Android front-end could be built to demo live detection.", "start": 773.016, "duration": 9.48}, {"index": 87, "sentence": "Extensibility: MicroScan can be expanded (e.g.", "start": 782.496, "duration": 4.824}, {"index": 88, "sentence": "to detect other pollutants or work with microscope attachments for other uses).", "start": 787.3199999999999, "duration": 6.096}, {"index": 89, "sentence": "The crowdsourcing aspect (map of plastic levels) adds a compelling “network effect” story.", "start": 793.4159999999999, "duration": 7.896}, {"index": 90, "sentence": "Judges often reward projects that can grow beyond a simple proof-of-concept.", "start": 801.3119999999999, "duration": 5.976}, {"index": 91, "sentence": "User Appeal: The solution is tangible and interactive.", "start": 807.2879999999999, "duration": 4.416}, {"index": 92, "sentence": "Users get immediate visual feedback (bounding boxes on detected particles) which is compelling to demo.", "start": 811.704, "duration": 8.52}, {"index": 93, "sentence": "The environmental angle and citizen-science twist make it memorable.", "start": 820.2239999999999, "duration": 4.992}, {"index": 94, "sentence": "With a clear real-world purpose and clever use of AI, MicroScan stands out as a “wow” project that both solves a real problem and showcases novel technology.", "start": 825.2159999999999, "duration": 13.224}, {"index": 95, "sentence": "References: Recent studies highlight the feasibility and importance of this idea.", "start": 838.4399999999999, "duration": 6.48}, {"index": 96, "sentence": "For instance, researchers have achieved 98% accuracy detecting microplastics using a smartphone microscope and YOLO model ( Deep-learning enabled rapid and low-cost detection of microplastics in consumer products following on-site extraction and image processing - PMC ).", "start": 844.92, "duration": 22.008}, {"index": 97, "sentence": "Another project built a portable chamber that images water samples and uses smartphone ML to quantify plastic (Northwest scientists develop a device that detects microplastics in water - OPB).", "start": 866.928, "duration": 15.6}, {"index": 98, "sentence": "These successes underscore that MicroScan’s approach is cutting-edge yet grounded in emerging science, positioning it as a high-impact hackathon project.", "start": 882.528, "duration": 11.64}]